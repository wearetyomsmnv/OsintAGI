# OSINT AGI - Набор скриптов из агентов, для выполнения OSINT задач.



## Установка

1. Клонируйте репозиторий:
```bash
git clone [URL репозитория]
cd OsintAGI
```

2. Создайте виртуальное окружение:
```bash
python -m venv venv
source venv/bin/activate  # для Linux/Mac
venv\Scripts\activate     # для Windows
```

3. Установите зависимости:
```bash
pip install -r requirements.txt
```

4. Создайте файл `.env` и добавьте необходимые API ключи:
```
SERPER_API_KEY=ваш_ключ
OPENAI_API=ваш_ключ
```

## Использование локальной модели через Ollama

CrewAI поддерживает работу с локальными моделями через Ollama. Это позволяет:
- Работать без подключения к интернету
- Обеспечить конфиденциальность данных
- Снизить затраты на API

### Установка Ollama

1. Скачайте и установите Ollama с официального сайта: [ollama.ai](https://ollama.ai)

2. Запустите нужную модель. Например:
```bash
ollama run llama3:70b
```

### Настройка CrewAI для работы с Ollama

1. В файле `osint_agi.py` добавьте конфигурацию LLM:
```python
from crewai import LLM

# Настройка локальной модели
llm = LLM(
    model="ollama/llama3:70b",  # или другая доступная модель
    base_url="http://localhost:11434"
)

# Использование в агентах
darknet_researcher = Agent(
    role='Исследователь даркнета',
    goal='Находить и анализировать информацию в даркнете',
    backstory="""Эксперт по исследованию даркнет-ресурсов...""",
    llm=llm,  # указываем нашу локальную модель
    tools=[search_tool],
    verbose=True
)
```

### Доступные локальные модели

Вы можете использовать различные модели, доступные через Ollama:
- llama2
- llama3:70b
- mistral
- mixtral
- codellama
- phi

Для установки новой модели используйте:
```bash
ollama pull название_модели
```

## Запуск исследования

1. Активируйте виртуальное окружение:
```bash
source venv/bin/activate  # для Linux/Mac
venv\Scripts\activate     # для Windows
```

2. Запустите скрипт:
```bash
python osint_agi.py
```

3. Введите цель для исследования когда будет запрошено.

## Результаты

Результаты исследования сохраняются в директории `osint_results` в формате текстовых файлов с временной меткой. Каждый отчет содержит:
- Информацию о цели исследования
- Найденные данные по каждому направлению
- Результаты верификации
- Технические детали
- Рекомендации по дальнейшему поиску


## Требования

- Python 3.8+
- Установленные зависимости из requirements.txt
- API ключи для используемых сервисов
- Для локальных моделей: установленная Ollama
